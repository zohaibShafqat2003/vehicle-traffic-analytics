# Phase 1 â€” Baseline End-to-End Traffic Pipeline ğŸš¦

## âœ… STATUS: COMPLETE (January 2026)

**Achievements:**
- âœ… End-to-end pipeline implemented and validated
- âœ… Click-to-calibrate tool for per-camera configuration
- âœ… Processed 4+ videos with stable outputs
- âœ… Optimized settings: 10 fps inference, 960px image size
- âœ… Track-based counting prevents double counts
- âœ… 15-minute aggregation working correctly
- âœ… CSV, XLSX, JSON, and annotated video outputs

---

## ğŸ“Œ Purpose

Phase 1 establishes a working end-to-end computer vision pipeline that processes a traffic video and produces 15-minute vehicle counts.

âš ï¸ **Accuracy is not the goal in Phase 1.**  
The objective is correct plumbing, tracking-based counting, and stable outputs.

---

## ğŸ¯ Phase 1 Goal

**Input:** Traffic video  
**Output:** Correctly aggregated 15-minute vehicle counts

This phase validates that:
- Video ingestion works
- Pretrained detection works
- Tracking prevents double counting
- Counting logic is correct
- Aggregation and exports are stable

---

## ğŸ§± Pipeline Overview (Phase 1 Scope)

```
Video
  â†“
Frame Extraction (FPS controlled)
  â†“
YOLO Pretrained Detection
  â†“
Multi-Object Tracking (ByteTrack / DeepSORT)
  â†“
Counting Logic (Line / ROI, track-based)
  â†“
15-Minute Aggregation
  â†“
CSV / XLSX / JSON Outputs
```

---

## ğŸ“‚ Directory Structure (Relevant to Phase 1)

```
src/
â”œâ”€â”€ process_video.py          # Main Phase-1 entrypoint
â”œâ”€â”€ ingest/
â”‚   â””â”€â”€ video_reader.py
â”œâ”€â”€ detect/
â”‚   â””â”€â”€ yolo_detector.py
â”œâ”€â”€ track/
â”‚   â””â”€â”€ tracker.py
â”œâ”€â”€ count/
â”‚   â”œâ”€â”€ counter.py
â”‚   â””â”€â”€ geometry.py
â”œâ”€â”€ aggregate/
â”‚   â””â”€â”€ time_bucketing.py
â”œâ”€â”€ export/
â”‚   â”œâ”€â”€ csv_writer.py
â”‚   â”œâ”€â”€ excel_writer.py
â”‚   â”œâ”€â”€ json_summary.py
â”‚   â””â”€â”€ video_annotator.py   # optional
configs/
â”œâ”€â”€ pipeline.yaml
â”œâ”€â”€ sites.yaml
â”œâ”€â”€ classes.yaml
out/
â”œâ”€â”€ counts/
â”‚   â”œâ”€â”€ counts_15min.csv
â”‚   â””â”€â”€ counts_15min.xlsx
â”œâ”€â”€ annotated_videos/         # optional
â””â”€â”€ run_summary.json
```

---

## ğŸ”§ Phase 1 Tasks & Responsibilities

### âœ… 1. Video Ingestion
- Read video using OpenCV
- Extract frames at configurable FPS (e.g. 10 FPS)
- Maintain:
  - `frame_index`
  - `t_sec` (timestamp in seconds)

### âœ… 2. Object Detection (Pretrained)
- Use YOLO pretrained weights
- For each frame:
  - `bbox` (x1,y1,x2,y2)
  - `class`
  - `confidence`
- **No custom training in Phase 1.**

### âœ… 3. Object Tracking
- Integrate ByteTrack (recommended) or DeepSORT
- Assign a stable `track_id` per object
- **Tracking is mandatory to avoid double counting**

### âœ… 4. Counting Logic (Critical)
**Counting is track-based, not frame-based.**

Supported rules:
- Line Crossing (recommended)
- ROI Entry

Rules:
- Each `track_id` is counted **only once**
- Count is triggered only on a **valid transition**
- Minimum track age is enforced to reduce noise

Stored as CountEvent:
```json
{
  "t_sec": 912.4,
  "site_id": "site_01",
  "track_id": 37,
  "class": "car",
  "rule": "line_crossing"
}
```

### âœ… 5. 15-Minute Aggregation
- Bucket size: **900 seconds**
- Bucket index:
```python
bucket = floor(t_sec / 900)
```
- Aggregated by:
  - `site_id`
  - time bucket
  - vehicle class

### âœ… 6. Outputs

**Mandatory:**
- `counts_15min.csv`
- `counts_15min.xlsx`
- `run_summary.json`

**Optional:**
- Annotated video with:
  - bbox
  - class
  - track_id
  - counting line / ROI

---

## ğŸ“Š Output Schema

### counts_15min.csv / xlsx
| bucket_start_sec | bucket_end_sec | site_id | vehicle_class | count |
|------------------|----------------|---------|---------------|-------|
| 0                | 900            | site_01 | car           | 12    |

### run_summary.json
Includes:
- Input video metadata
- FPS used
- Model name & version
- Tracker parameters
- Total counts per class
- Run timestamp

---

## ğŸ§ª Acceptance Criteria (Phase 1)

âœ… Pipeline runs on a single video  
âœ… No double counting in simple scenes  
âœ… Each vehicle counted once per rule  
âœ… 15-minute buckets align exactly  
âœ… Output format remains stable  

---

## âš ï¸ Known Limitations (Accepted in Phase 1)

- Class accuracy may be weak (qingqi, axles not reliable yet)
- Occlusions and dense traffic may cause missed tracks
- Night / rain / glare not handled fully

**These are addressed in Phase 2 & 3 (training + tuning).**

---

## ğŸš€ How to Run (Example)

```bash
python src/process_video.py \
  --input data/sample.mp4 \
  --site site_01 \
  --config configs/pipeline.yaml \
  --out out/
```

---

## ğŸ”œ What Comes After Phase 1

- **Phase 2:** Dataset creation & labeling
- **Phase 3:** Custom YOLO training (Pakistan traffic)
- **Phase 4:** Accuracy evaluation & calibration
- **Phase 5:** Multi-site + production hardening

---

## ğŸ§  Design Philosophy

âœ… **Track once â†’ count once**  
âœ… **Deterministic aggregation**  
âœ… **Debug visually first**  
âœ… **Correctness before accuracy**
